name: Anime Adventures Value List Scraper

on:
  schedule:
    - cron: '0 9 * * *'  # Runs at 9:00 AM UTC daily
  workflow_dispatch:      # Allows manual triggering

jobs:
  scrape:
    runs-on: ubuntu-latest
    permissions:
      contents: write     # Explicitly grant permission to push changes

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          fetch-depth: 0  # Fetch all history for proper git operations

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Setup Chrome
        uses: browser-actions/setup-chrome@v1
        with:
          chrome-version: stable

      - name: Setup ChromeDriver
        uses: nanasess/setup-chromedriver@v2

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install requests beautifulsoup4 selenium pandas openpyxl xlsxwriter

      - name: Verify Chrome and ChromeDriver
        run: |
          google-chrome --version
          chromedriver --version

      - name: Run scraper
        run: python scrape_anime_adventures_by_section.py
        
      - name: Check for new files
        id: check_files
        run: |
          if ls Anime_Adventures_Value_List*.xlsx 2>/dev/null; then
            echo "files_exist=true" >> $GITHUB_OUTPUT
          else
            echo "files_exist=false" >> $GITHUB_OUTPUT
          fi

      - name: Commit and push changes
        if: steps.check_files.outputs.files_exist == 'true'
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add Anime_Adventures_Value_List*.xlsx
          git commit -m "Daily update: $(date +'%Y-%m-%d')"
          git push